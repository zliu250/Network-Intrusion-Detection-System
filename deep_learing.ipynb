{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read in CSV\n",
    "train_pd = pd.read_csv('train.csv')\n",
    "test_pd = pd.read_csv('test.csv')\n",
    "\n",
    "# Convert string representation of list to actual list of floats\n",
    "train_pd['features'] = train_pd['features'].apply(lambda x: [float(i) for i in x.strip('[]').split(',')])\n",
    "test_pd['features'] = test_pd['features'].apply(lambda x: [float(i) for i in x.strip('[]').split(',')])\n",
    "\n",
    "x_train = torch.from_numpy(np.array(train_pd['features'].values.tolist(), np.float32))\n",
    "y_train = torch.from_numpy(np.array(train_pd['outcome'].values.tolist(), np.int64))\n",
    "\n",
    "x_test = torch.from_numpy(np.array(test_pd['features'].values.tolist(), np.float32))\n",
    "y_test = torch.from_numpy(np.array(test_pd['outcome'].values.tolist(), np.int64))\n",
    "\n",
    "# Make sure the data is zero-indexed\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "print(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125973, 113]) torch.Size([125973])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "train_dataset = MyDataset(x_train, y_train)\n",
    "test_dataset = MyDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear(input_size, 128)\n",
    "        self.ln2 = nn.Linear(128, 64)\n",
    "        self.ln3 = nn.Linear(64, 32)\n",
    "        self.ln4 = nn.Linear(32, 5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ln1(x))\n",
    "        x = F.relu(self.ln2(x))\n",
    "        x = F.relu(self.ln3(x))\n",
    "        x = self.ln4(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, model, lr, batch_size):\n",
    "    model = model.to(device)\n",
    "\n",
    "    batch_size = batch_size\n",
    "    num_epochs = n_epochs\n",
    "    lr = lr\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        # Initialize variables to store the total loss for this epoch\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        # Training loop\n",
    "        for batch_id, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)  # Move the data to the device that is used\n",
    "            opt.zero_grad()  # Zero the gradients\n",
    "            output = model(x)  # Forward pass\n",
    "            loss = loss_fcn(output, y)  # Compute the loss\n",
    "\n",
    "            total_train_loss += loss.item()  # Accumulate the loss\n",
    "            _, predicted = torch.max(output.data, 1)  # Get the predicted classes\n",
    "            total_predictions += y.size(0)\n",
    "            correct_predictions += (predicted == y).sum().item()\n",
    "            loss.backward()  # Backward pass\n",
    "            opt.step()  # Update the parameters\n",
    "\n",
    "        # Store the average training loss for this epoch\n",
    "        train_loss.append(total_train_loss / len(train_loader))\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1} - Train Accuracy: {correct_predictions / total_predictions}\")\n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        with torch.no_grad():  # No need to compute gradients during validation\n",
    "            for batch_id, (x, y) in enumerate(test_loader):\n",
    "                x, y = x.to(device), y.to(device)  # Move the data to the device that is used\n",
    "                output = model(x)  # Forward pass\n",
    "                loss = loss_fcn(output, y )  # Compute the loss\n",
    "                total_test_loss += loss.item()  # Accumulate the loss\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total_predictions += y.size(0)\n",
    "                correct_predictions += (predicted == y).sum().item()\n",
    "\n",
    "        # Store the average validation loss for this epoch\n",
    "        test_loss.append(total_test_loss / len(test_loader))\n",
    "\n",
    "        # Print the losses every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1} - Train Loss: {train_loss[-1]}, Test Loss: {test_loss[-1]}\")\n",
    "            print(f\"Epoch {epoch + 1} - Test Accuracy: {correct_predictions / total_predictions}\")\n",
    "\n",
    "        # Save the best model so far\n",
    "        if epoch == 0 or test_loss[-1] < np.min(test_loss[:-1]):\n",
    "            best_model = model\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch - best_epoch >= 30:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    # Plot the training and validation losses\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_loss, label=\"Train Loss\")\n",
    "    plt.plot(test_loss, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and Validation Losses\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Accuracy: 0.9747723718574616\n",
      "Epoch 5 - Train Loss: 0.9300287121443579, Test Loss: 1.1809837797940788\n",
      "Epoch 5 - Test Accuracy: 0.7229418026969482\n",
      "Epoch 10 - Train Accuracy: 0.9740817476760893\n",
      "Epoch 10 - Train Loss: 0.9307262445464352, Test Loss: 1.1771779585692843\n",
      "Epoch 10 - Test Accuracy: 0.7267565649396736\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train.shape[1]\n",
    "models = myNeuralNet(input_size)\n",
    "training_loop(10, models, 0.004, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
